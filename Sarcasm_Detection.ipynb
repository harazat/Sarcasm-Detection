{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIBkwOZ3e_GI"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "data = list(parse_data('/content/Sarcasm_Headlines_Dataset_v2.json'))\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qCLpWwTUv-P"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "pJxOy0sG5NsF",
    "outputId": "7f9cf16e-1a16-4d8a-e0bb-f64861e1433e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "      <th>model_truth_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>1</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>1</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>0</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic  ... model_truth_values\n",
       "0                 1  ...             [0, 1]\n",
       "1                 0  ...             [1, 0]\n",
       "2                 0  ...             [1, 0]\n",
       "3                 1  ...             [0, 1]\n",
       "4                 1  ...             [0, 1]\n",
       "...             ...  ...                ...\n",
       "28614             1  ...             [0, 1]\n",
       "28615             1  ...             [0, 1]\n",
       "28616             0  ...             [1, 0]\n",
       "28617             1  ...             [0, 1]\n",
       "28618             1  ...             [0, 1]\n",
       "\n",
       "[28619 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = df[\"headline\"]\n",
    "df['model_truth_values'] = df['is_sarcastic'].apply(lambda input: [0,1] if input == 1 else [1,0] )\n",
    "# df['is_sarcastic']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhK8Dz9RCO1m"
   },
   "outputs": [],
   "source": [
    "sarcastic_headlines = [i['headline']  for i in data if i['is_sarcastic'] == 1 ]\n",
    "not_sarcastic_headlines = [i['headline']  for i in data if i['is_sarcastic'] == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "S-JtezgUA9Nu",
    "outputId": "20c0daf6-0155-4380-8ac4-67a792c0690a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my white inheritance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 ways to file your taxes with less stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lots of parents know this scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>what our grieving family needs from loved ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>stephen colbert attempts to list everything tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>bakery owner vows to stop making wedding cakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>how san antonio's dominant defense is fueling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14985 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0      dem rep. totally nails why congress is falling...\n",
       "1      eat your veggies: 9 deliciously different recipes\n",
       "2                                   my white inheritance\n",
       "3             5 ways to file your taxes with less stress\n",
       "4                     lots of parents know this scenario\n",
       "...                                                  ...\n",
       "14980  what our grieving family needs from loved ones...\n",
       "14981  stephen colbert attempts to list everything tr...\n",
       "14982  bakery owner vows to stop making wedding cakes...\n",
       "14983  how san antonio's dominant defense is fueling ...\n",
       "14984  the most beautiful acceptance speech this week...\n",
       "\n",
       "[14985 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(not_sarcastic_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Wu_sIlVDhTJ",
    "outputId": "128b4bfc-d6ff-4bb0-c4a0-03a01505c97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 9.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 41.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 52.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 6.6MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "all_headlines = df.headline.values\n",
    "all_headlines\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhwypbqpFgyR"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# xlmr = torch.hub.load('pytorch/fairseq', 'xlmr.large')\n",
    "# xlmr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "471452d1ae9c45529a2ea4091cdb8ceb",
      "1ac38f5c54204583ae4613c3d68c86ed",
      "bc61c6fd9ce34f018073112b2053857b",
      "dbcf3369e78e4c96b7517bb91111d419",
      "e702a78659a9442b8c272fdb8b92992e",
      "93f9785e500d4d01886bda685a0669eb",
      "46b7032b7cb3408c8c7d6ad373d1a360",
      "bd1edbb138544ad2a964848d5676af11",
      "1055fca42fec4b0ea97bbf823decff8b",
      "fb534d0dc90c4d799d09302dd54aeadf",
      "2f055c163f3d48b087b90fec75771fd0",
      "1a674cdce2ba4482a64d9e205a072c6a",
      "e62cd4d4e6e84650b1be9859e109f7c0",
      "b51cd9c63145444ab3df8d962ec3a4cb",
      "31b3de8b0ae44e23a66cabc391078d5a",
      "07c3fdff92694ae49ab4e72201aa11bd",
      "34fafba330164bf98d58aa71b4defa91",
      "01eb44b728514c778b76daf144b16020",
      "56fee448f41347568062aa8b129f7915",
      "3cac4cd63301412492e823a6b2a296f0",
      "6d9b869078334367bf982296087057e1",
      "c4d7e64c8d384db88aba64893fd240b8",
      "acd31aede8ef43e2b66c9e0283f30040",
      "06a96b3c418346b6b3519060cfa6eb5c",
      "f27554747c5d4ac4827a0a7d8d85ac79",
      "33de41458a96429f891171cbb1637806",
      "6bbd6e8bfa97442a90726bc27fac4100",
      "19e831760b1f4b1285e3f2057d3bf992",
      "9494a3adf47f42359a5b10c3962aa191",
      "0f1ed2dde73241a18cccbe85952071ec",
      "499fa6476b8440ef9193c6a04d7a5854",
      "290a7f84ebae448589ff440422c8ee89"
     ]
    },
    "id": "tl8saG5-zmVl",
    "outputId": "08540e52-b823-4890-e127-7a786b4c67b1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471452d1ae9c45529a2ea4091cdb8ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1055fca42fec4b0ea97bbf823decff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PreTrainedTokenizer(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fafba330164bf98d58aa71b4defa91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27554747c5d4ac4827a0a7d8d85ac79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "print(tokenizer)\n",
    "model = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtKO3F5z1cGG",
    "outputId": "6392cb58-2247-4335-c651-5f5ab63ab67b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 35378,  8999,    38,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rc3-MYSO7Ehh",
    "outputId": "fa3c6767-ab1f-4ce3-9858-8ab11a8f63ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ticoTqM7AIJB",
    "outputId": "c897064b-39d3-4b96-dbc1-3dfc46f417d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fP90d0SKBB3m",
    "outputId": "6a2f2fd0-fbff-4120-c150-192f8c40af30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['last_hidden_state'][0,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CX0z7lbXCmfS"
   },
   "outputs": [],
   "source": [
    "def get_BERT_input(headlines, tokenizer):\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  encoded_dict = tokenizer.batch_encode_plus(\n",
    "                      headlines,                      # Sentence to encode.\n",
    "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                      max_length = 65,           # Pad & truncate all sentences.\n",
    "                      pad_to_max_length = True,\n",
    "                      return_attention_mask = True,   # Construct attn. masks.\n",
    "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                )\n",
    "  input_ids, attention_mask = encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "  # Add the encoded sentence to the list.    \n",
    "  input_ids = encoded_dict['input_ids']\n",
    "  \n",
    "  # And its attention mask (simply differentiates padding from non-padding).\n",
    "  attention_mask = encoded_dict['attention_mask']\n",
    "  return torch.tensor(input_ids), torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PuSG72vvS0H",
    "outputId": "914da535-18c0-4383-bdbb-a630e5386c3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[     0,    903,     83,     10, 111719,   7986,      2,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "               1,      1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_BERT_input([\"this is a plain text\"], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sMcJu4z-fU8"
   },
   "source": [
    "#Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liDUMi6ZwjQg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.headlines = df[\"headline\"]\n",
    "        self.model_truth_values = df[\"model_truth_values\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.headlines.iloc[idx], torch.tensor(self.model_truth_values.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmIuw9aG2Y0m"
   },
   "outputs": [],
   "source": [
    "dataset = SarcasmDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P23P9lRx3Byj",
    "outputId": "d1d6c69e-f082-4df4-db9b-1944233003ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inclement weather prevents liar from getting to work', tensor([0, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcX4CNsK3Clb"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPReR79K3hdO",
    "outputId": "7df47cc8-b28a-4586-e53f-3969c8a32633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7efc2be50b90>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVuB2IcU5VCd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSDPcMX-7Q3E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwZwBLVs-ZG-"
   },
   "source": [
    "#Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUPr3-JW-cLX",
    "outputId": "1bd0638d-67df-4cbb-cf61-b29472c152d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "class SarcasmModel(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(SarcasmModel, self).__init__()\n",
    "      self.XLM = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "      self.hidden_1 = nn.Linear(768, 128)\n",
    "      self.hidden_2 = nn.Linear(128, 2)\n",
    "      #self.hidden_3 = nn.Linear(16,2)\n",
    "      self.softMax = nn.Softmax(dim=1)\n",
    "      self.to_delete = 2\n",
    "\n",
    "    def forward(self, batch_input_ids, batch_attention_mask):\n",
    "      bert_output = self.XLM(batch_input_ids, batch_attention_mask)\n",
    "      # print(batch_input_ids.shape)\n",
    "      # print(batch_attention_mask.shape)\n",
    "      hidden_state = bert_output['last_hidden_state']\n",
    "      sentence_vector = torch.mean(hidden_state, dim = 1)\n",
    "      #print(sentence_vector.shape)\n",
    "      x = self.hidden_1(sentence_vector)\n",
    "      x = self.hidden_2(x)\n",
    "     # x = self.hidden_3(x)\n",
    "      probabilities = self.softMax(x)\n",
    "      #print(probabilities)\n",
    "      return probabilities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SarcasmModel()\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BhNH-x4JwR0"
   },
   "source": [
    "#Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aM7YZU2c_HOw",
    "outputId": "73acb9f3-7a47-4341-e9f4-baa2209a7a85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: tensor(0.0983, device='cuda:0')\n",
      "Batch Accuracy: tensor(91.7406, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.0983, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 320 Loss: tensor(0.1245, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.2663, device='cuda:0')\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 640 Loss: tensor(0.0436, device='cuda:0')\n",
      "Batch Accuracy: tensor(96.1400, device='cuda:0')\n",
      "tensor(0.0436, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 960 Loss: tensor(0.2543, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.6785, device='cuda:0')\n",
      "tensor(0.2543, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 1280 Loss: tensor(0.1923, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.3871, device='cuda:0')\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 1600 Loss: tensor(0.1078, device='cuda:0')\n",
      "Batch Accuracy: tensor(96.6537, device='cuda:0')\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 1920 Loss: tensor(0.0530, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.4718, device='cuda:0')\n",
      "tensor(0.0530, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 2240 Loss: tensor(0.0936, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.2670, device='cuda:0')\n",
      "tensor(0.0936, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 2560 Loss: tensor(0.1049, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.6486, device='cuda:0')\n",
      "tensor(0.1049, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 2880 Loss: tensor(0.1100, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.4259, device='cuda:0')\n",
      "tensor(0.1100, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 3200 Loss: tensor(0.0202, device='cuda:0')\n",
      "Batch Accuracy: tensor(98.0762, device='cuda:0')\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 3520 Loss: tensor(0.0421, device='cuda:0')\n",
      "Batch Accuracy: tensor(96.9661, device='cuda:0')\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 3840 Loss: tensor(0.0783, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.4930, device='cuda:0')\n",
      "tensor(0.0783, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 4160 Loss: tensor(0.0907, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.0545, device='cuda:0')\n",
      "tensor(0.0907, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 4480 Loss: tensor(0.0786, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.3493, device='cuda:0')\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 4800 Loss: tensor(0.0360, device='cuda:0')\n",
      "Batch Accuracy: tensor(96.7361, device='cuda:0')\n",
      "tensor(0.0360, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 5120 Loss: tensor(0.0236, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.8373, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 5440 Loss: tensor(0.2700, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.0403, device='cuda:0')\n",
      "tensor(0.2700, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 5760 Loss: tensor(0.0959, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.9103, device='cuda:0')\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 6080 Loss: tensor(0.1799, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.2704, device='cuda:0')\n",
      "tensor(0.1799, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 6400 Loss: tensor(0.1882, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.0844, device='cuda:0')\n",
      "tensor(0.1882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 6720 Loss: tensor(0.0299, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.5553, device='cuda:0')\n",
      "tensor(0.0299, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 7040 Loss: tensor(0.0856, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.3608, device='cuda:0')\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 7360 Loss: tensor(0.2110, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.6155, device='cuda:0')\n",
      "tensor(0.2110, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 7680 Loss: tensor(0.1584, device='cuda:0')\n",
      "Batch Accuracy: tensor(89.4560, device='cuda:0')\n",
      "tensor(0.1584, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 8000 Loss: tensor(0.0772, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.5089, device='cuda:0')\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 8320 Loss: tensor(0.0247, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.6456, device='cuda:0')\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 8640 Loss: tensor(0.0484, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.7865, device='cuda:0')\n",
      "tensor(0.0484, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 8960 Loss: tensor(0.1439, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.7491, device='cuda:0')\n",
      "tensor(0.1439, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 9280 Loss: tensor(0.1337, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.6480, device='cuda:0')\n",
      "tensor(0.1337, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 9600 Loss: tensor(0.2000, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.5513, device='cuda:0')\n",
      "tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 9920 Loss: tensor(0.1296, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.8539, device='cuda:0')\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 10240 Loss: tensor(0.1313, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.4120, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.1313, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 10560 Loss: tensor(0.2057, device='cuda:0')\n",
      "Batch Accuracy: tensor(91.5447, device='cuda:0')\n",
      "tensor(0.2057, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 10880 Loss: tensor(0.1235, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.7246, device='cuda:0')\n",
      "tensor(0.1235, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 11200 Loss: tensor(0.2622, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.5995, device='cuda:0')\n",
      "tensor(0.2622, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 11520 Loss: tensor(0.3913, device='cuda:0')\n",
      "Batch Accuracy: tensor(84.3502, device='cuda:0')\n",
      "tensor(0.3913, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 11840 Loss: tensor(0.2014, device='cuda:0')\n",
      "Batch Accuracy: tensor(87.9970, device='cuda:0')\n",
      "tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 12160 Loss: tensor(0.1394, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.3229, device='cuda:0')\n",
      "tensor(0.1394, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 12480 Loss: tensor(0.1175, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.1328, device='cuda:0')\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 12800 Loss: tensor(0.2359, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.0821, device='cuda:0')\n",
      "tensor(0.2359, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 13120 Loss: tensor(0.1693, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.1952, device='cuda:0')\n",
      "tensor(0.1693, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 13440 Loss: tensor(0.1683, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.1264, device='cuda:0')\n",
      "tensor(0.1683, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 13760 Loss: tensor(0.1736, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.3749, device='cuda:0')\n",
      "tensor(0.1736, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 14080 Loss: tensor(0.1014, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.2782, device='cuda:0')\n",
      "tensor(0.1014, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 14400 Loss: tensor(0.0186, device='cuda:0')\n",
      "Batch Accuracy: tensor(98.2157, device='cuda:0')\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 14720 Loss: tensor(0.0756, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.6993, device='cuda:0')\n",
      "tensor(0.0756, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 15040 Loss: tensor(0.0772, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.4756, device='cuda:0')\n",
      "tensor(0.0772, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 15360 Loss: tensor(0.1762, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.2952, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.1762, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 15680 Loss: tensor(0.0905, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.6171, device='cuda:0')\n",
      "tensor(0.0905, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 16000 Loss: tensor(0.5079, device='cuda:0')\n",
      "Batch Accuracy: tensor(84.6039, device='cuda:0')\n",
      "tensor(0.5079, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 16320 Loss: tensor(0.0726, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.1205, device='cuda:0')\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 16640 Loss: tensor(0.1735, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.4849, device='cuda:0')\n",
      "tensor(0.1735, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 16960 Loss: tensor(0.0286, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.4075, device='cuda:0')\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 17280 Loss: tensor(0.0272, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.5201, device='cuda:0')\n",
      "tensor(0.0272, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 17600 Loss: tensor(0.1339, device='cuda:0')\n",
      "Batch Accuracy: tensor(91.8624, device='cuda:0')\n",
      "tensor(0.1339, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 17920 Loss: tensor(0.0739, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.1561, device='cuda:0')\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 18240 Loss: tensor(0.1633, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.3839, device='cuda:0')\n",
      "tensor(0.1633, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 18560 Loss: tensor(0.0569, device='cuda:0')\n",
      "Batch Accuracy: tensor(96.3571, device='cuda:0')\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 18880 Loss: tensor(0.1501, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.3452, device='cuda:0')\n",
      "tensor(0.1501, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 19200 Loss: tensor(0.1072, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.1996, device='cuda:0')\n",
      "tensor(0.1072, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 19520 Loss: tensor(0.1852, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.7634, device='cuda:0')\n",
      "tensor(0.1852, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 19840 Loss: tensor(0.1259, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.0203, device='cuda:0')\n",
      "tensor(0.1259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 20160 Loss: tensor(0.3283, device='cuda:0')\n",
      "Batch Accuracy: tensor(86.1498, device='cuda:0')\n",
      "tensor(0.3283, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 20480 Loss: tensor(0.0828, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.6964, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 20800 Loss: tensor(0.0603, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.0625, device='cuda:0')\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 21120 Loss: tensor(0.1232, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.0785, device='cuda:0')\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 21440 Loss: tensor(0.1107, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.9402, device='cuda:0')\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 21760 Loss: tensor(0.3553, device='cuda:0')\n",
      "Batch Accuracy: tensor(87.9515, device='cuda:0')\n",
      "tensor(0.3553, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 22080 Loss: tensor(0.1010, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.8491, device='cuda:0')\n",
      "tensor(0.1010, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 22400 Loss: tensor(0.1397, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.5825, device='cuda:0')\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 22720 Loss: tensor(0.2142, device='cuda:0')\n",
      "Batch Accuracy: tensor(89.2786, device='cuda:0')\n",
      "tensor(0.2142, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 23040 Loss: tensor(0.1818, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.7708, device='cuda:0')\n",
      "tensor(0.1818, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 23360 Loss: tensor(0.0519, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.4915, device='cuda:0')\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 23680 Loss: tensor(0.2434, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.5390, device='cuda:0')\n",
      "tensor(0.2434, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 24000 Loss: tensor(0.1572, device='cuda:0')\n",
      "Batch Accuracy: tensor(87.9681, device='cuda:0')\n",
      "tensor(0.1572, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 24320 Loss: tensor(0.0882, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.0159, device='cuda:0')\n",
      "tensor(0.0882, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 24640 Loss: tensor(0.2012, device='cuda:0')\n",
      "Batch Accuracy: tensor(89.9522, device='cuda:0')\n",
      "tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 24960 Loss: tensor(0.0830, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.3221, device='cuda:0')\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 25280 Loss: tensor(0.0264, device='cuda:0')\n",
      "Batch Accuracy: tensor(97.5385, device='cuda:0')\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 25600 Loss: tensor(0.2004, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.6414, device='cuda:0')\n",
      "Saved Model\n",
      "tensor(0.2004, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 25920 Loss: tensor(0.0965, device='cuda:0')\n",
      "Batch Accuracy: tensor(92.1864, device='cuda:0')\n",
      "tensor(0.0965, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 26240 Loss: tensor(0.0496, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.5565, device='cuda:0')\n",
      "tensor(0.0496, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 26560 Loss: tensor(0.0698, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.2251, device='cuda:0')\n",
      "tensor(0.0698, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 26880 Loss: tensor(0.0497, device='cuda:0')\n",
      "Batch Accuracy: tensor(95.5208, device='cuda:0')\n",
      "tensor(0.0497, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 27200 Loss: tensor(0.0673, device='cuda:0')\n",
      "Batch Accuracy: tensor(94.6281, device='cuda:0')\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 27520 Loss: tensor(0.1396, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.9490, device='cuda:0')\n",
      "tensor(0.1396, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 27840 Loss: tensor(0.0734, device='cuda:0')\n",
      "Batch Accuracy: tensor(93.9818, device='cuda:0')\n",
      "tensor(0.0734, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 28160 Loss: tensor(0.1947, device='cuda:0')\n",
      "Batch Accuracy: tensor(88.5471, device='cuda:0')\n",
      "tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Iteration: 28480 Loss: tensor(0.1604, device='cuda:0')\n",
      "Batch Accuracy: tensor(90.7882, device='cuda:0')\n",
      "tensor(0.1604, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.BCELoss().to(device)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr=2e-5,\n",
    "                 eps=1e-8)\n",
    "batch_size = 32\n",
    "for step, (batch_headlines, batch_model_truth_values) in enumerate(train_dataloader):  #(inputs, outputs)\n",
    "  batch_model_truth_values = batch_model_truth_values.to(device)\n",
    "  optimizer.zero_grad()\n",
    "  batch_input_ids, batch_attention_mask = get_BERT_input(batch_headlines, tokenizer)\n",
    "  batch_prediction = model(batch_input_ids.to(device), batch_attention_mask.to(device))\n",
    "  loss = loss_function(batch_prediction, batch_model_truth_values.float())\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "\n",
    "  if step % 10 == 0:\n",
    "      iteration = step*batch_size\n",
    "      print(\"Iteration:\", step*batch_size, \"Loss:\", loss.data)\n",
    "      batch_accuracy = torch.mean(torch.sum(batch_prediction * batch_model_truth_values.to(device), dim=1))\n",
    "      print(\"Batch Accuracy:\", batch_accuracy.data*100)\n",
    "      if iteration % 5120 == 0:\n",
    "        # torch.save(model.state_dict(), expt_folder + \"SarcasmModel.pt\")\n",
    "        print(\"Saved Model\")\n",
    "  #print(loss)\n",
    "  # print(batch_input_ids.shape)\n",
    "  # print(batch_attention_mask.shape)\n",
    "  # print(step)\n",
    "  # print(batch_headlines[0])\n",
    "  # print(batch_model_truth_values[0])\n",
    "  if step % 10 == 0:\n",
    "    print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-EfYFgd4Ki0",
    "outputId": "ed9d064a-c96a-429e-9e06-843fc5f92ecf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Sarcastic:', '96.46', 'Not Sarcastic:', '3.54')"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(b_headline, tokenizer, model):\n",
    "  batch_input_ids, batch_attention_mask = get_BERT_input(batch_headlines, tokenizer)\n",
    "  batch_predictions = model(batch_input_ids.to(device), batch_attention_mask.to(device))\n",
    "  sarcastic_probability = batch_predictions.data[0][1].item() * 100\n",
    "  not_sarcastic_probability = batch_predictions.data[0][0].item() * 100\n",
    "  print_string = \"Sarcastic:\", f'{sarcastic_probability:.2f}', \"Not Sarcastic:\", f'{not_sarcastic_probability:.2f}'\n",
    "  # return b_predictions\n",
    "  return print_string \n",
    "\n",
    "predict([\"հայաստանում լիքը փող կա\"], tokenizer, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THqMcrnDeK2G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sarcasm Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01eb44b728514c778b76daf144b16020": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06a96b3c418346b6b3519060cfa6eb5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07c3fdff92694ae49ab4e72201aa11bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f1ed2dde73241a18cccbe85952071ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1055fca42fec4b0ea97bbf823decff8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f055c163f3d48b087b90fec75771fd0",
       "IPY_MODEL_1a674cdce2ba4482a64d9e205a072c6a"
      ],
      "layout": "IPY_MODEL_fb534d0dc90c4d799d09302dd54aeadf"
     }
    },
    "19e831760b1f4b1285e3f2057d3bf992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_290a7f84ebae448589ff440422c8ee89",
      "placeholder": "​",
      "style": "IPY_MODEL_499fa6476b8440ef9193c6a04d7a5854",
      "value": " 1.12G/1.12G [00:23&lt;00:00, 46.7MB/s]"
     }
    },
    "1a674cdce2ba4482a64d9e205a072c6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07c3fdff92694ae49ab4e72201aa11bd",
      "placeholder": "​",
      "style": "IPY_MODEL_31b3de8b0ae44e23a66cabc391078d5a",
      "value": " 9.10M/9.10M [00:01&lt;00:00, 5.66MB/s]"
     }
    },
    "1ac38f5c54204583ae4613c3d68c86ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "290a7f84ebae448589ff440422c8ee89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f055c163f3d48b087b90fec75771fd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b51cd9c63145444ab3df8d962ec3a4cb",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e62cd4d4e6e84650b1be9859e109f7c0",
      "value": 9096718
     }
    },
    "31b3de8b0ae44e23a66cabc391078d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33de41458a96429f891171cbb1637806": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34fafba330164bf98d58aa71b4defa91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56fee448f41347568062aa8b129f7915",
       "IPY_MODEL_3cac4cd63301412492e823a6b2a296f0"
      ],
      "layout": "IPY_MODEL_01eb44b728514c778b76daf144b16020"
     }
    },
    "3cac4cd63301412492e823a6b2a296f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06a96b3c418346b6b3519060cfa6eb5c",
      "placeholder": "​",
      "style": "IPY_MODEL_acd31aede8ef43e2b66c9e0283f30040",
      "value": " 512/512 [00:26&lt;00:00, 19.5B/s]"
     }
    },
    "46b7032b7cb3408c8c7d6ad373d1a360": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "471452d1ae9c45529a2ea4091cdb8ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc61c6fd9ce34f018073112b2053857b",
       "IPY_MODEL_dbcf3369e78e4c96b7517bb91111d419"
      ],
      "layout": "IPY_MODEL_1ac38f5c54204583ae4613c3d68c86ed"
     }
    },
    "499fa6476b8440ef9193c6a04d7a5854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56fee448f41347568062aa8b129f7915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4d7e64c8d384db88aba64893fd240b8",
      "max": 512,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d9b869078334367bf982296087057e1",
      "value": 512
     }
    },
    "6bbd6e8bfa97442a90726bc27fac4100": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f1ed2dde73241a18cccbe85952071ec",
      "max": 1115590446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9494a3adf47f42359a5b10c3962aa191",
      "value": 1115590446
     }
    },
    "6d9b869078334367bf982296087057e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "93f9785e500d4d01886bda685a0669eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9494a3adf47f42359a5b10c3962aa191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "acd31aede8ef43e2b66c9e0283f30040": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b51cd9c63145444ab3df8d962ec3a4cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc61c6fd9ce34f018073112b2053857b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93f9785e500d4d01886bda685a0669eb",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e702a78659a9442b8c272fdb8b92992e",
      "value": 5069051
     }
    },
    "bd1edbb138544ad2a964848d5676af11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4d7e64c8d384db88aba64893fd240b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbcf3369e78e4c96b7517bb91111d419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd1edbb138544ad2a964848d5676af11",
      "placeholder": "​",
      "style": "IPY_MODEL_46b7032b7cb3408c8c7d6ad373d1a360",
      "value": " 5.07M/5.07M [00:29&lt;00:00, 170kB/s]"
     }
    },
    "e62cd4d4e6e84650b1be9859e109f7c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e702a78659a9442b8c272fdb8b92992e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f27554747c5d4ac4827a0a7d8d85ac79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bbd6e8bfa97442a90726bc27fac4100",
       "IPY_MODEL_19e831760b1f4b1285e3f2057d3bf992"
      ],
      "layout": "IPY_MODEL_33de41458a96429f891171cbb1637806"
     }
    },
    "fb534d0dc90c4d799d09302dd54aeadf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
